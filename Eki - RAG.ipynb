{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"le3eKcvRgYdM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716554744918,"user_tz":-120,"elapsed":29956,"user":{"displayName":"Juliette LACROIX","userId":"10175103258104132512"}},"outputId":"604c6c7f-e1b2-4d7c-dc0f-ba9b9a867b0a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Hackathon Master Data Sciences & Business Analytics\n","\n","Don't forget to enable GPU on the running instance to run it faster (Execution > Modify execution type)"],"metadata":{"id":"TGbIc-kQC4w7"}},{"cell_type":"markdown","source":["# Install some libraries"],"metadata":{"id":"Mr37UIg9C4LO"}},{"cell_type":"code","source":["%pip install langchain langchain-community  gradio sentence-transformers tiktoken langchain-groq faiss-gpu -q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"bgnDXGYuC1cM","executionInfo":{"status":"ok","timestamp":1716554839032,"user_tz":-120,"elapsed":94123,"user":{"displayName":"Juliette LACROIX","userId":"10175103258104132512"}},"outputId":"55153636-863a-426c-cc2b-1cf4a29708dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/973.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m870.4/973.5 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.5/973.5 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.5/308.5 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.8/122.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.9/315.9 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n","weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"markdown","source":["# Import some libraries"],"metadata":{"id":"K465L0dmC3UY"}},{"cell_type":"code","source":["\n","import shutil\n","import pickle\n","import tempfile\n","from operator import itemgetter\n","import time\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import gradio as gr\n","\n","import os\n","import yaml\n","from tqdm import tqdm\n","from langchain.prompts.prompt import PromptTemplate\n","from typing import Tuple, List\n","from langchain.schema.runnable import RunnableMap\n","from langchain.schema import format_document\n","from datetime import datetime\n","from operator import itemgetter\n","from langchain.memory import ConversationBufferMemory\n","\n","from langchain.document_loaders import DataFrameLoader, TextLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.prompts import ChatPromptTemplate\n","from langchain.schema.output_parser import StrOutputParser\n","from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n","from langchain.vectorstores import FAISS\n","from langchain.schema import Document, HumanMessage, BaseMessage\n","from langchain.schema.chat_history import BaseChatMessageHistory\n","from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n","from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n","from langchain.callbacks.base import AsyncCallbackHandler, BaseCallbackManager\n","from langchain.globals import set_llm_cache\n","\n","from langchain_groq import ChatGroq\n"],"metadata":{"id":"IkuGVdDdC68C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define some functions"],"metadata":{"id":"7CeOa_1gF_AY"}},{"cell_type":"code","source":["def _combine_documents(\n","    docs, document_prompt, document_separator=\"\\n\\n\"\n","):\n","    doc_strings = [\n","        f\"Document {i}: \\n'''\\n{format_document(doc, document_prompt)}\\n'''\"\n","        for i, doc in enumerate(docs, 1)\n","    ]\n","    return document_separator.join(doc_strings)\n","\n","\n","def _format_chat_history(chat_history: List[Tuple]) -> str:\n","    turn = 1\n","    buffer = []\n","    for dialogue in chat_history:\n","        buffer.append((\"Human: \" if turn else \"Assistant: \") + dialogue.content)\n","        turn ^= 1\n","    return \"\\n\".join(buffer) + \"\\n\"\n","\n","\n","def make_pairs(lst):\n","    \"\"\"from a list of even lenght, make tupple pairs\"\"\"\n","    return [(lst[i], lst[i + 1]) for i in range(0, len(lst), 2)]\n","\n","\n","def make_html_source(i, doc):\n","    return f\"\"\"\n","<div class=\"card\">\n","  <div class=\"card-content\">\n","      <h3>Doc {i}</h2>\n","      <p>{BeautifulSoup(doc.page_content, 'html.parser')}</p>\n","  </div>\n","  <div class=\"card-footer\">\n","    <span>page: {doc.metadata['page_number']}</span>\n","  </div>\n","</div>\n","\"\"\"\n","\n","async def chat(\n","    query: str,\n","    history: list = [],\n","    length: str = \"Medium\",\n","    language: str = \"the same language of the question\",\n","    audience: str = \"public\",\n","    tone: str = \"formal\"\n","):\n","    \"\"\"taking a query and a message history, use a pipeline (reformulation, retriever, answering) to yield a tuple of:\n","    (messages in gradio format, messages in langchain format, source documents)\"\"\"\n","    source_string = \"\"\n","    gradio_format = make_pairs([a.content for a in history]) + [(query, \"\")]\n","\n","    # reset memory\n","    memory.clear()\n","    for message in history:\n","        memory.chat_memory.add_message(message)\n","\n","    inputs = {\"question\": query, \"length\": length, \"language\": language, \"audience\": audience, \"tone\": tone}\n","    result = final_chain.astream_log(inputs)\n","\n","    reformulated_question_path_id = \"/logs/ChatGroq/streamed_output_str/-\"\n","    retriever_path_id = \"/logs/Retriever/final_output\"\n","    final_answer_path_id = \"/logs/ChatGroq:2/streamed_output_str/-\"\n","\n","    async for op in result:\n","        op = op.ops[0]\n","        if op[\"path\"] == reformulated_question_path_id:  # reforulated question\n","            new_token = op[\"value\"]  # str\n","\n","        elif op[\"path\"] == retriever_path_id:  # documents\n","            sources = op[\"value\"][\"documents\"]  # List[Document]\n","            source_string = \"\\n\\n\".join(\n","                [make_html_source(i, doc) for i, doc in enumerate(sources, 1)]\n","            )\n","\n","        elif op[\"path\"] == final_answer_path_id:  # final answer\n","            new_token = op[\"value\"]  # str\n","            answer_yet = gradio_format[-1][1]\n","            gradio_format[-1] = (query, answer_yet + new_token)\n","\n","        yield \"\", gradio_format, history, source_string\n","\n","    memory.save_context(inputs, {\"answer\": gradio_format[-1][1]})\n","    yield \"\", gradio_format, memory.load_memory_variables({})[\"history\"], source_string"],"metadata":{"id":"TQuvFczaF-Tg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define global params"],"metadata":{"id":"LfZ11IKIDlDO"}},{"cell_type":"code","source":["demo_name = \"Hackathon climate Q-A\"\n","\n","# Put your token from https://console.groq.com/keys\n","os.environ[\"GROQ_API_KEY\"] = \"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\""],"metadata":{"id":"AW-ita8bDmM1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Treat data"],"metadata":{"id":"vVAT_JXrFfsp"}},{"cell_type":"markdown","source":["## Load and prepare parsed data"],"metadata":{"id":"w201Zr9HFhC2"}},{"cell_type":"code","source":["documents = []\n","path_data = \"/content/drive/MyDrive/Group 6/data/\" # maybe need to be adapted"],"metadata":{"id":"3ihCYI57lbyO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for file in tqdm(os.listdir(path_data)):\n","  if file.endswith('.parquet'):\n","    df = pd.read_parquet(os.path.join(path_data, file))\n","    df = df[df[\"sub_type\"] == \"Text\"]\n","    df = df[[\"content\", \"file_name\", \"page_number\"]]\n","    loader = DataFrameLoader(df, page_content_column=\"content\")\n","    text_splitter = RecursiveCharacterTextSplitter(\n","        chunk_size=256, chunk_overlap=50, length_function=lambda x: len(x.split())\n","    )\n","\n","  docs = loader.load_and_split(text_splitter)\n","  documents.extend(docs)"],"metadata":{"id":"-LK170icFi3r","executionInfo":{"status":"ok","timestamp":1716555050445,"user_tz":-120,"elapsed":41238,"user":{"displayName":"Juliette LACROIX","userId":"10175103258104132512"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9ee9635f-b60d-4331-bbf2-f6295fe0d1b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 15/15 [00:40<00:00,  2.69s/it]\n"]}]},{"cell_type":"markdown","source":["## Get embeddings, vectorstore and retriever"],"metadata":{"id":"su1H1Zn972pA"}},{"cell_type":"code","source":["model_name = \"BAAI/bge-small-en\"\n","encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n","print(\"Loading embeddings model: \", model_name)\n","embeddings = HuggingFaceBgeEmbeddings(\n","    model_name=model_name,\n","    encode_kwargs=encode_kwargs,\n","    query_instruction=\"Represent this sentence for searching relevant passages: \"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"vN-8j2Uq8EOQ","outputId":"c5d97cdf-6b03-4df7-ec16-7a5bb0affc92"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Loading embeddings model:  BAAI/bge-small-en\n"]}]},{"cell_type":"code","source":["# Around 3mins with GPU enabled\n","vectorstore = FAISS.from_documents(\n","    documents, embedding=embeddings,\n",")\n","\n","retriever = vectorstore.as_retriever()"],"metadata":{"id":"_J37ojTvPiJj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["retriever.invoke(\"What is climate change ?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iE2qdR6NmV0o","executionInfo":{"status":"ok","timestamp":1716555361098,"user_tz":-120,"elapsed":611,"user":{"displayName":"Juliette LACROIX","userId":"10175103258104132512"}},"outputId":"b30b598d-c6ec-47c2-954a-9c75d6ee8619"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Document(page_content='Climate Change. https://doi.org/10.1038/\\r\\nnclimate3382', metadata={'file_name': '202206-IPBES-GLOBAL-REPORT-FULL-DIGITAL-MARCH-2022.pdf', 'page_number': 786}),\n"," Document(page_content=\"Climate change A change in the state of the climate that can be \\r\\nidentified (e.g., by using statistical tests) by changes in the mean and/\\r\\nor the variability of its properties and that persists for an extended \\r\\nperiod, typically decades or longer. Climate change may be due to \\r\\nnatural internal processes or external forcings such as modulations \\r\\nof the solar cycles, volcanic eruptions and persistent anthropogenic\\r\\nchanges in the composition of the atmosphere or in land use. Note \\r\\nthat the United Nations Framework Convention on Climate Change \\r\\n(UNFCCC), in its Article 1, defines climate change as: 'a change of \\r\\nclimate which is attributed directly or indirectly to human activity \\r\\nthat alters the composition of the global atmosphere and which is \\r\\nin addition to natural climate variability observed over comparable \\r\\ntime periods'. The UNFCCC thus makes a distinction between climate \\r\\nchange attributable to human activities altering the atmospheric \\r\\ncomposition and climate variability attributable to natural causes. See \\r\\nalso Climate variability, Detection and attribution, Global warming\\r\\nand Ocean acidification (OA).\", metadata={'file_name': 'First-Assessment-Report-on-the-Physical-Science-of-Climate-Change.pdf', 'page_number': 2238}),\n"," Document(page_content=\"Climate change A change in the state of the climate that can be \\r\\nidentified (e.g., by using statistical tests) by changes in the mean and/\\r\\nor the variability of its properties and that persists for an extended \\r\\nperiod, typically decades or longer. Climate change may be due to \\r\\nnatural internal processes or external forcings such as modulations \\r\\nof the solar cycles, volcanic eruptions and persistent anthropogenic\\r\\nchanges in the composition of the atmosphere or in land use. Note \\r\\nthat the United Nations Framework Convention on Climate Change \\r\\n(UNFCCC), in its Article 1, defines climate change as: 'a change of \\r\\nclimate which is attributed directly or indirectly to human activity \\r\\nthat alters the composition of the global atmosphere and which is \\r\\nin addition to natural climate variability observed over comparable \\r\\ntime periods'. The UNFCCC thus makes a distinction between climate \\r\\nchange attributable to human activities altering the atmospheric \\r\\ncomposition and climate variability attributable to natural causes. See \\r\\nalso Climate variability, Detection and attribution, Global warming\\r\\nand Ocean acidification (OA).\", metadata={'file_name': 'First-Assessment-Report-on-the-Physical-Science-of-Climate-Change.pdf', 'page_number': 2238}),\n"," Document(page_content=\"Climate change A change in the state of the climate that can be \\r\\nidentified (e.g., by using statistical tests) by changes in the mean and/\\r\\nor the variability of its properties and that persists for an extended \\r\\nperiod, typically decades or longer. Climate change may be due to \\r\\nnatural internal processes or external forcings such as modulations \\r\\nof the solar cycles, volcanic eruptions and persistent anthropogenic\\r\\nchanges in the composition of the atmosphere or in land use. Note \\r\\nthat the United Nations Framework Convention on Climate Change \\r\\n(UNFCCC), in its Article 1, defines climate change as: 'a change of \\r\\nclimate which is attributed directly or indirectly to human activity \\r\\nthat alters the composition of the global atmosphere and which is \\r\\nin addition to natural climate variability observed over comparable \\r\\ntime periods'. The UNFCCC thus makes a distinction between climate \\r\\nchange attributable to human activities altering the atmospheric \\r\\ncomposition and climate variability attributable to natural causes.\", metadata={'file_name': 'Third-Assessment-Report-on-Climate-Change-Mitigation.pdf', 'page_number': 1809})]"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["## Get LLM from Groq"],"metadata":{"id":"6Go_0566Fn85"}},{"cell_type":"code","source":["chat_model = ChatGroq(temperature=0, model_name=\"llama3-8b-8192\") # llama3-70b-8192 / mixtral-8x7b-32768"],"metadata":{"id":"v0zTeQ81GlLG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Create a prompt"],"metadata":{"id":"24rY9ZYRH73S"}},{"cell_type":"code","source":["reformulation_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n","\n","Chat History:\n","{chat_history}\n","Follow Up Input: {question}\n","Standalone question:\"\"\"\n","\n","CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(reformulation_template)\n","\n","answering_template = \"\"\"\n","  You are ClimateQ&A, an AI Assistant created by Ekimetrics. You are given a question and extracted passages of the IPCC and/or IPBES reports. Provide a clear and structured answer based on the passages provided, the context and the guidelines.\n","\n","  Guidelines:\n","  - If the passages have useful facts or numbers, use them in your answer.\n","  - When you use information from a passage, mention where it came from by using [Doc i] at the end of the sentence. i stands for the number of the document.\n","  - Do not use the sentence 'Doc i says ...' to say where information came from.\n","  - If the same thing is said in more than one document, you can mention all of them like this: [Doc i, Doc j, Doc k]\n","  - Do not just summarize each passage one by one. Group your summaries to highlight the key parts in the explanation.\n","  - If it makes sense, use bullet points and lists to make your answers easier to understand.\n","  - You do not need to use every passage. Only use the ones that help answer the question.\n","  - If the documents do not have the information needed to answer the question, just say you do not have enough information.\n","  - Consider by default that the question is about the past century unless it is specified otherwise.\n","  - If the passage is the caption of a picture, you can still use it as part of your answer as any other document.\n","\n","  Your answer should be {length}.\n","  Answer in {language}.\n","  You should have an {tone} tone.\n","  You should speak as if you were speaking to {audience}\n","  -----------------------\n","  Passages:\n","  {context}\n","\n","  -----------------------\n","  Question: {question}\n","  Answer with the passages citations:\n","  \"\"\"\n","\n","ANSWER_PROMPT = ChatPromptTemplate.from_template(answering_template)\n","\n","DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}.\\page: {page_number}\")"],"metadata":{"id":"6q_J8G7nF18z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Chain some functions"],"metadata":{"id":"oYPbZGcxINb_"}},{"cell_type":"code","source":["memory = ConversationBufferMemory(\n","    return_messages=True, output_key=\"answer\", input_key=\"question\"\n",")\n","\n","# First we add a step to load memory\n","# This adds a \"memory\" key to the input object\n","loaded_memory = RunnablePassthrough.assign(\n","    chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"),\n",")\n","\n","# Now we calculate the standalone question\n","standalone_question = {\n","    \"standalone_question\": {\n","        \"question\": lambda x: x[\"question\"],\n","        \"chat_history\": lambda x: _format_chat_history(x[\"chat_history\"]),\n","    }\n","    | CONDENSE_QUESTION_PROMPT\n","    | chat_model\n","    | StrOutputParser(),\n","    \"length\": lambda x: x[\"length\"],\n","    \"language\": lambda x: x[\"language\"],\n","    \"audience\": lambda x: x[\"audience\"],\n","    \"tone\": lambda x: x[\"tone\"],\n","}\n","\n","# Now we retrieve the documents\n","retrieved_documents = {\n","    \"docs\": itemgetter(\"standalone_question\") | retriever,\n","    \"question\": lambda x: x[\"standalone_question\"],\n","    \"length\": lambda x: x[\"length\"],\n","    \"language\": lambda x: x[\"language\"],\n","    \"audience\": lambda x: x[\"audience\"],\n","    \"tone\": lambda x: x[\"tone\"],\n","}\n","\n","# Now we construct the inputs for the final prompt\n","final_inputs = {\n","    \"context\": lambda x: _combine_documents(x[\"docs\"], DEFAULT_DOCUMENT_PROMPT),\n","    \"question\": itemgetter(\"question\"),\n","    \"length\": itemgetter(\"length\"),\n","    \"language\": itemgetter(\"language\"),\n","    \"audience\": itemgetter(\"audience\"),\n","    \"tone\": itemgetter(\"tone\")\n","}\n","\n","# And finally, we do the part that returns the answers\n","answer = {\n","    \"answer\": final_inputs | ANSWER_PROMPT | chat_model,\n","    \"docs\": itemgetter(\"docs\"),\n","}\n","\n","# And now we put it all together!\n","final_chain = loaded_memory | standalone_question | retrieved_documents | answer"],"metadata":{"id":"qGLwOKbiGUdH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Setup your Gradio"],"metadata":{"id":"tQQQdxEQIQuC"}},{"cell_type":"markdown","source":["## Get CSS styling"],"metadata":{"id":"GeI6r8pRIW7F"}},{"cell_type":"code","source":["with open(\"./drive/MyDrive/Group 6/Assets/style.css\", \"r\") as f:# maybe path need to be adapted\n","    css = f.read()"],"metadata":{"id":"xDA3Nbo6GZOH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Create your app"],"metadata":{"id":"bZArHGG4IZhz"}},{"cell_type":"code","source":["with gr.Blocks(title=f\"{demo_name}\", css=css) as demo:\n","\n","    gr.Markdown(f\"<h1><center>{demo_name}</center></h1>\")\n","\n","    with gr.Row():\n","        with gr.Column(scale=2):\n","            chatbot = gr.Chatbot(\n","                elem_id=\"chatbot\", label=f\"{demo_name} chatbot\", show_label=False\n","            )\n","            state = gr.State([])\n","\n","            # Add the drop-down box here\n","            length = gr.Dropdown(\n","                choices=[\"Very short\", \"Short\", \"Medium\", \"Long\", \"Very long\"],\n","                label=\"Select response length\"\n","            )\n","\n","            language = gr.Dropdown(\n","                choices=[\"English\", \"French\", \"Italian\", \"Spanish\"],\n","                label=\"Select language\",\n","                value=\"the same language of the question\"\n","            )\n","\n","            audience = gr.Dropdown(\n","                choices=[\"Children\", \"Public\", \"Experts\"],\n","                label=\"Select audience\"\n","            )\n","\n","            tone = gr.Dropdown(\n","                choices=[\"Informal\", \"Formal\", \"Dramatic\", \"Fun\"],\n","                label=\"Select tone\"\n","            )\n","\n","            with gr.Row():\n","                ask = gr.Textbox(\n","                    show_label=False,\n","                    placeholder=\"Input your question then press enter\",\n","                )\n","\n","        with gr.Column(scale=1, variant=\"panel\"):\n","            gr.Markdown(\"### Sources\")\n","            sources_textbox = gr.Markdown(show_label=False)\n","\n","        ask.submit(\n","            fn=chat,\n","            inputs=[\n","                ask,\n","                state,\n","                length,\n","                language,\n","                audience,\n","                tone\n","            ],\n","            outputs=[ask, chatbot, state, sources_textbox],\n","        )\n","\n","demo.launch(\n","    share=True,\n","    # auth=(\"\", \"\"),\n","    debug=True\n",")"],"metadata":{"id":"D0tc_GE5Gbtx","colab":{"base_uri":"https://localhost:8080/","height":784},"outputId":"97198b84-38ac-4624-8b15-f89e5d2e706f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gradio/components/dropdown.py:181: UserWarning: The value passed into gr.Dropdown() is not in the list of choices. Please update the list of choices to include: the same language of the question or set allow_custom_value=True.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","Running on public URL: https://85012fb7166d393245.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://85012fb7166d393245.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["<ipython-input-62-948639ad7765>:30: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  <p>{BeautifulSoup(doc.page_content, 'html.parser')}</p>\n","<ipython-input-62-948639ad7765>:30: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  <p>{BeautifulSoup(doc.page_content, 'html.parser')}</p>\n","<ipython-input-62-948639ad7765>:30: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  <p>{BeautifulSoup(doc.page_content, 'html.parser')}</p>\n","<ipython-input-62-948639ad7765>:30: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  <p>{BeautifulSoup(doc.page_content, 'html.parser')}</p>\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"skt67vO2AXnZ"},"execution_count":null,"outputs":[]}]}